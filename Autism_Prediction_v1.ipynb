{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab681a3",
   "metadata": {},
   "source": [
    "# ML Olympiad - Autism Prediction Challenge - By: Kaggle\n",
    "\n",
    "<h3>Objective: </h3>\n",
    "Improve Autism Screening by creating predicting the likelihood of having this condition.\n",
    "\n",
    "<h3>Causes and Challenges:</h3>\n",
    "It is mostly influenced by a combination of genetic and environmental factors. Because autism is a spectrum disorder, each person with autism has a distinct set of strengths and challenges. The ways in which people with autism learn, think and problem-solve can range from highly skilled to severely challenged. Research has made clear that high quality early intervention can improve learning, communication and social skills, as well as underlying brain development. Yet the diagnostic process can take several years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf90d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "781e96ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>7.819715</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Australia</td>\n",
       "      <td>no</td>\n",
       "      <td>10.544296</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>no</td>\n",
       "      <td>13.167506</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>no</td>\n",
       "      <td>1.530098</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Black</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Italy</td>\n",
       "      <td>no</td>\n",
       "      <td>7.949723</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0   1         1         0         1         1         1         1         0   \n",
       "1   2         0         0         0         0         0         0         0   \n",
       "2   3         1         1         1         1         1         1         0   \n",
       "3   4         0         0         0         1         0         0         0   \n",
       "4   5         0         0         0         0         1         0         0   \n",
       "\n",
       "   A8_Score  A9_Score  ...  gender       ethnicity jaundice austim  \\\n",
       "0         1         1  ...       f  White-European       no     no   \n",
       "1         0         0  ...       f     South Asian       no     no   \n",
       "2         0         1  ...       f  White-European       no     no   \n",
       "3         0         0  ...       f     South Asian       no     no   \n",
       "4         0         1  ...       m           Black       no    yes   \n",
       "\n",
       "    contry_of_res used_app_before     result     age_desc  relation Class/ASD  \n",
       "0   United States              no   7.819715  18 and more      Self         0  \n",
       "1       Australia              no  10.544296  18 and more         ?         0  \n",
       "2  United Kingdom              no  13.167506  18 and more      Self         1  \n",
       "3     New Zealand              no   1.530098  18 and more         ?         0  \n",
       "4           Italy              no   7.949723  18 and more      Self         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = pd.read_csv('train.csv')\n",
    "print(at.shape)\n",
    "at.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f69d732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "at.drop(['ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba8a48fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score           0\n",
       "A2_Score           0\n",
       "A3_Score           0\n",
       "A4_Score           0\n",
       "A5_Score           0\n",
       "A6_Score           0\n",
       "A7_Score           0\n",
       "A8_Score           0\n",
       "A9_Score           0\n",
       "A10_Score          0\n",
       "age                0\n",
       "gender             0\n",
       "ethnicity          0\n",
       "jaundice           0\n",
       "austim             0\n",
       "contry_of_res      0\n",
       "used_app_before    0\n",
       "result             0\n",
       "age_desc           0\n",
       "relation           0\n",
       "Class/ASD          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d318f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ethnicity', 'relation'], dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We observe that even though there are no nulls we have '?' in place of missing values\n",
    "\n",
    "at.columns[at.isin({'?'}).sum() > 0] # Columns with ? in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1ec8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert ? to Null\n",
    "\n",
    "at = at.replace({'?' : np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f79c396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score             0\n",
       "A2_Score             0\n",
       "A3_Score             0\n",
       "A4_Score             0\n",
       "A5_Score             0\n",
       "A6_Score             0\n",
       "A7_Score             0\n",
       "A8_Score             0\n",
       "A9_Score             0\n",
       "A10_Score            0\n",
       "age                  0\n",
       "gender               0\n",
       "ethnicity          151\n",
       "jaundice             0\n",
       "austim               0\n",
       "contry_of_res        0\n",
       "used_app_before      0\n",
       "result               0\n",
       "age_desc             0\n",
       "relation            77\n",
       "Class/ASD            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.isnull().sum() # We can now see the missing value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "82cbc1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity NaNs :\n",
      "  White-European     211\n",
      "Asian              134\n",
      "Middle Eastern     116\n",
      "Black               45\n",
      "Latino              44\n",
      "South Asian         35\n",
      "Others              24\n",
      "Pasifika            18\n",
      "Hispanic            16\n",
      "Turkish              4\n",
      "others               2\n",
      "Name: ethnicity, dtype: int64\n",
      "\n",
      " Relation NaNs :\n",
      "  Self                        617\n",
      "Parent                       49\n",
      "Relative                     43\n",
      "Health care professional      7\n",
      "Others                        7\n",
      "Name: relation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Ethnicity NaNs :\\n ',at['ethnicity'].value_counts()) # we can replace \n",
    "print('\\n Relation NaNs :\\n ',at['relation'].value_counts()) # we can replace self for nulls in Relation col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31ad28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Nulls with the above observed logical values\n",
    "\n",
    "at['relation'] = at['relation'].fillna('Self')\n",
    "at['ethnicity'] = at['ethnicity'].fillna('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c3e7d05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   A1_Score         800 non-null    int64  \n",
      " 1   A2_Score         800 non-null    int64  \n",
      " 2   A3_Score         800 non-null    int64  \n",
      " 3   A4_Score         800 non-null    int64  \n",
      " 4   A5_Score         800 non-null    int64  \n",
      " 5   A6_Score         800 non-null    int64  \n",
      " 6   A7_Score         800 non-null    int64  \n",
      " 7   A8_Score         800 non-null    int64  \n",
      " 8   A9_Score         800 non-null    int64  \n",
      " 9   A10_Score        800 non-null    int64  \n",
      " 10  age              800 non-null    float64\n",
      " 11  gender           800 non-null    object \n",
      " 12  ethnicity        800 non-null    object \n",
      " 13  jaundice         800 non-null    object \n",
      " 14  austim           800 non-null    object \n",
      " 15  contry_of_res    800 non-null    object \n",
      " 16  used_app_before  800 non-null    object \n",
      " 17  result           800 non-null    float64\n",
      " 18  age_desc         800 non-null    object \n",
      " 19  relation         800 non-null    object \n",
      " 20  Class/ASD        800 non-null    int64  \n",
      "dtypes: float64(2), int64(11), object(8)\n",
      "memory usage: 131.4+ KB\n"
     ]
    }
   ],
   "source": [
    "at.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "15446072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f    415\n",
      "m    385\n",
      "Name: gender, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "White-European     211\n",
      "others             153\n",
      "Asian              134\n",
      "Middle Eastern     116\n",
      "Black               45\n",
      "Latino              44\n",
      "South Asian         35\n",
      "Others              24\n",
      "Pasifika            18\n",
      "Hispanic            16\n",
      "Turkish              4\n",
      "Name: ethnicity, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "no     604\n",
      "yes    196\n",
      "Name: jaundice, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "no     683\n",
      "yes    117\n",
      "Name: austim, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "United States           148\n",
      "United Arab Emirates     94\n",
      "New Zealand              93\n",
      "India                    74\n",
      "United Kingdom           58\n",
      "                       ... \n",
      "Indonesia                 1\n",
      "Tonga                     1\n",
      "Iraq                      1\n",
      "Finland                   1\n",
      "Niger                     1\n",
      "Name: contry_of_res, Length: 61, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "no     765\n",
      "yes     35\n",
      "Name: used_app_before, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "18 and more    800\n",
      "Name: age_desc, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "Self                        694\n",
      "Parent                       49\n",
      "Relative                     43\n",
      "Health care professional      7\n",
      "Others                        7\n",
      "Name: relation, dtype: int64\n",
      "++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "col = at.columns\n",
    "\n",
    "for i in col:\n",
    "    if(at[i].dtype == 'object'):\n",
    "        print(at[i].value_counts())\n",
    "        print('++++++++++++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "857d7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Label Encoder to all Object type columns \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "at[at.select_dtypes(include = ['object']).columns] = at[at.select_dtypes(include = ['object']).columns].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "611df149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   A1_Score         800 non-null    int64  \n",
      " 1   A2_Score         800 non-null    int64  \n",
      " 2   A3_Score         800 non-null    int64  \n",
      " 3   A4_Score         800 non-null    int64  \n",
      " 4   A5_Score         800 non-null    int64  \n",
      " 5   A6_Score         800 non-null    int64  \n",
      " 6   A7_Score         800 non-null    int64  \n",
      " 7   A8_Score         800 non-null    int64  \n",
      " 8   A9_Score         800 non-null    int64  \n",
      " 9   A10_Score        800 non-null    int64  \n",
      " 10  age              800 non-null    float64\n",
      " 11  gender           800 non-null    int32  \n",
      " 12  ethnicity        800 non-null    int32  \n",
      " 13  jaundice         800 non-null    int32  \n",
      " 14  austim           800 non-null    int32  \n",
      " 15  contry_of_res    800 non-null    int32  \n",
      " 16  used_app_before  800 non-null    int32  \n",
      " 17  result           800 non-null    float64\n",
      " 18  age_desc         800 non-null    int32  \n",
      " 19  relation         800 non-null    int32  \n",
      " 20  Class/ASD        800 non-null    int64  \n",
      "dtypes: float64(2), int32(8), int64(11)\n",
      "memory usage: 106.4 KB\n"
     ]
    }
   ],
   "source": [
    "at.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd078cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Balance the Classes to get proper Result based on both kinds of data\n",
    "\n",
    "at_label = pd.DataFrame(at[at['Class/ASD'] == 1]) \n",
    "at_label2 = pd.DataFrame(at[at['Class/ASD'] == 1]) \n",
    "\n",
    "at = pd.concat([at, at_label, at_label2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fdb45fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.605397</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>7.819715</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.829369</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10.544296</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.679893</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>13.167506</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.035288</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1.530098</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.256686</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>7.949723</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0         1         0         1         1         1         1         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         1         1         1         1         1         1         0   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         0         1         0         0   \n",
       "\n",
       "   A8_Score  A9_Score  A10_Score        age  gender  ethnicity  jaundice  \\\n",
       "0         1         1          1  18.605397       0          9         0   \n",
       "1         0         0          1  13.829369       0          7         0   \n",
       "2         0         1          1  14.679893       0          9         0   \n",
       "3         0         0          0  61.035288       0          7         0   \n",
       "4         0         1          1  14.256686       1          1         0   \n",
       "\n",
       "   austim  contry_of_res  used_app_before     result  age_desc  relation  \n",
       "0       0             58                0   7.819715         0         4  \n",
       "1       0              6                0  10.544296         0         4  \n",
       "2       0             57                0  13.167506         0         4  \n",
       "3       0             39                0   1.530098         0         4  \n",
       "4       1             32                0   7.949723         0         4  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_x = at.drop(['Class/ASD'], axis =1 )\n",
    "at_y = at['Class/ASD']\n",
    "\n",
    "at_x_train, at_x_test, at_y_train, at_y_test = train_test_split(at_x, at_y, test_size=.2)\n",
    "at_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7d435839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_lst = []\n",
    "\n",
    "AccuracyScore = []\n",
    "PrecisionScore = []\n",
    "Recall_Score = []\n",
    "F1_score = []\n",
    "Roc_Scr = []\n",
    "\n",
    "\n",
    "def model_scores(model_name, model_obj):\n",
    "    \n",
    "    pred_y = model_obj.predict(at_x_test)\n",
    "    \n",
    "#     print(pred_y)\n",
    "    \n",
    "#     ConfusionMatrix = confusion_matrix(pr_test_y, pr_pred_y) \n",
    "#     print('ConfusionMatrix')\n",
    "#     print(ConfusionMatrix,'\\n')\n",
    "\n",
    "    AccuracyScore.append(np.round((model_obj.score(at_x_test, at_y_test))*100))\n",
    "\n",
    "    PrecisionScore.append(((precision_score(at_y_test, pred_y))*100).round(2))\n",
    "\n",
    "    Recall_Score.append(((recall_score(at_y_test, pred_y))*100).round(2))\n",
    "\n",
    "    F1_score.append(((f1_score(at_y_test, pred_y))*100).round(2))\n",
    "\n",
    "    Roc_Scr.append(((roc_auc_score(at_y_test, pred_y))*100).round(2))\n",
    "\n",
    "    model_name_lst.append(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f93bab",
   "metadata": {},
   "source": [
    "<h3>Logistic Regression classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "35bee8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter  =500)\n",
    "logreg.fit(at_x_train, at_y_train)\n",
    "\n",
    "pred_y = logreg.predict(at_x_test)\n",
    "\n",
    "model_scores('Logistic Reg', logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3539f5e",
   "metadata": {},
   "source": [
    "<h3>Decision Tree Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2f3756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dt.fit(at_x_train, at_y_train)\n",
    "model_scores('Decision Tree', dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2f56e",
   "metadata": {},
   "source": [
    "<h3>Random Forest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a7233a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2)\n",
    "rf.fit(at_x_train, at_y_train)\n",
    "model_scores('Random Forest', rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df69ff",
   "metadata": {},
   "source": [
    "<h3>K nearest Neigbours Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ad0c09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KNeighborsClassifier(n_neighbors=22)\n",
    "kn.fit(at_x_train, at_y_train)\n",
    "model_scores('KNearestNeigbour', kn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5120a5",
   "metadata": {},
   "source": [
    "<h3>Support Vector Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "687c202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'poly', degree=10)\n",
    "svc.fit(at_x_train, at_y_train)\n",
    "model_scores('SVC',svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52779107",
   "metadata": {},
   "source": [
    "<h3>XG Boost Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58aee256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRIME\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgbr = XGBClassifier(verbosity = 0)\n",
    "xgbr.fit(at_x_train, at_y_train)\n",
    "model_scores('XGBoost', xgbr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d4005d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Roc Scr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>96.0</td>\n",
       "      <td>94.66</td>\n",
       "      <td>97.64</td>\n",
       "      <td>96.12</td>\n",
       "      <td>95.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>97.0</td>\n",
       "      <td>94.07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.95</td>\n",
       "      <td>96.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>77.0</td>\n",
       "      <td>93.98</td>\n",
       "      <td>61.42</td>\n",
       "      <td>74.29</td>\n",
       "      <td>78.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Reg</th>\n",
       "      <td>89.0</td>\n",
       "      <td>89.76</td>\n",
       "      <td>89.76</td>\n",
       "      <td>89.76</td>\n",
       "      <td>88.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>90.0</td>\n",
       "      <td>86.11</td>\n",
       "      <td>97.64</td>\n",
       "      <td>91.51</td>\n",
       "      <td>89.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNearestNeigbour</th>\n",
       "      <td>76.0</td>\n",
       "      <td>85.29</td>\n",
       "      <td>68.50</td>\n",
       "      <td>75.98</td>\n",
       "      <td>77.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy Score  Precision Score  Recall Score  F1 score  \\\n",
       "Random Forest               96.0            94.66         97.64     96.12   \n",
       "XGBoost                     97.0            94.07        100.00     96.95   \n",
       "SVC                         77.0            93.98         61.42     74.29   \n",
       "Logistic Reg                89.0            89.76         89.76     89.76   \n",
       "Decision Tree               90.0            86.11         97.64     91.51   \n",
       "KNearestNeigbour            76.0            85.29         68.50     75.98   \n",
       "\n",
       "                  Roc Scr  \n",
       "Random Forest       95.55  \n",
       "XGBoost             96.26  \n",
       "SVC                 78.37  \n",
       "Logistic Reg        88.81  \n",
       "Decision Tree       89.47  \n",
       "KNearestNeigbour    77.24  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores = pd.DataFrame({'Accuracy Score' : AccuracyScore, 'Precision Score': PrecisionScore, 'Recall Score': Recall_Score, 'F1 score': F1_score, 'Roc Scr':Roc_Scr}, index= [model_name_lst])\n",
    "df = Scores.sort_values('Precision Score', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bbc500",
   "metadata": {},
   "source": [
    "<h2> Now lets try using Deep Learning Techniques to predict Autism </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34c8fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noramlize the Independent Variable to get better results\n",
    "\n",
    "at_x_train = tf.keras.utils.normalize(at_x_train)\n",
    "at_x_test = tf.keras.utils.normalize(at_x_test)\n",
    "\n",
    "# Convert Dataframe to Array in order to convert use Tensorflow\n",
    "at_x_train = np.array(at_x_train)\n",
    "at_x_test = np.array(at_x_test)\n",
    "at_y_train = np.array(at_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44a2e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential() # modelis initialized\n",
    "model.add(tf.keras.layers.Dense(128, activation= tf.nn.relu)) # 1st Hidden Layer\n",
    "model.add(tf.keras.layers.Dense(128, activation= tf.nn.relu)) # 2st Hidden Layer\n",
    "model.add(tf.keras.layers.Dense(128, activation= tf.nn.relu)) # 3st Hidden Layer\n",
    "model.add(tf.keras.layers.Dense(2, activation= tf.nn.softmax)) # 10 is not a hyper parameter\n",
    "# number of layers in target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f15579a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'adam' optimizer (like the GD)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eba84aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(at_x_train, at_y_train, epochs=50, validation_split=.2, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40e7e477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(at_x_test)\n",
    "y_pred = np.argmax(y_pred, axis =1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "73608b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " Actual Values -> Predicted Values\n",
      " \n",
      " [[ 92  15]\n",
      " [ 15 112]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       107\n",
      "           1       0.88      0.88      0.88       127\n",
      "\n",
      "    accuracy                           0.87       234\n",
      "   macro avg       0.87      0.87      0.87       234\n",
      "weighted avg       0.87      0.87      0.87       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "tab = confusion_matrix(at_y_test, y_pred)\n",
    "print('Confusion Matrix : \\n Actual Values -> Predicted Values\\n \\n',tab)\n",
    "print('\\n',classification_report(at_y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c732b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Roc Scr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>96.0</td>\n",
       "      <td>94.66</td>\n",
       "      <td>97.64</td>\n",
       "      <td>96.12</td>\n",
       "      <td>95.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>97.0</td>\n",
       "      <td>94.07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>96.95</td>\n",
       "      <td>96.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>77.0</td>\n",
       "      <td>93.98</td>\n",
       "      <td>61.42</td>\n",
       "      <td>74.29</td>\n",
       "      <td>78.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Reg</th>\n",
       "      <td>89.0</td>\n",
       "      <td>89.76</td>\n",
       "      <td>89.76</td>\n",
       "      <td>89.76</td>\n",
       "      <td>88.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>90.0</td>\n",
       "      <td>86.11</td>\n",
       "      <td>97.64</td>\n",
       "      <td>91.51</td>\n",
       "      <td>89.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNearestNeigbour</th>\n",
       "      <td>76.0</td>\n",
       "      <td>85.29</td>\n",
       "      <td>68.50</td>\n",
       "      <td>75.98</td>\n",
       "      <td>77.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy Score  Precision Score  Recall Score  F1 score  \\\n",
       "Random Forest               96.0            94.66         97.64     96.12   \n",
       "XGBoost                     97.0            94.07        100.00     96.95   \n",
       "SVC                         77.0            93.98         61.42     74.29   \n",
       "Logistic Reg                89.0            89.76         89.76     89.76   \n",
       "Decision Tree               90.0            86.11         97.64     91.51   \n",
       "KNearestNeigbour            76.0            85.29         68.50     75.98   \n",
       "\n",
       "                  Roc Scr  \n",
       "Random Forest       95.55  \n",
       "XGBoost             96.26  \n",
       "SVC                 78.37  \n",
       "Logistic Reg        88.81  \n",
       "Decision Tree       89.47  \n",
       "KNearestNeigbour    77.24  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4425feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've have managed to achieve High precision with Random Forest \n",
    "\n",
    "# Hence, we will now train our entire model with complete train.csv and predict on test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "799448ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=100, max_depth=30, min_samples_split=2)\n",
    "rf1.fit(at_x, at_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "503adcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=10, kernel='poly')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel = 'poly', degree=10)\n",
    "svc.fit(at_x, at_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a87fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRIME\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr = XGBClassifier(verbosity = 0)\n",
    "xgbr.fit(at_x, at_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f99b155e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter  = 500)\n",
    "logreg.fit(at_x, at_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bbb3497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.read_csv('test.csv')\n",
    "\n",
    "tf1 = tf.copy()\n",
    "tf = tf.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fbe8091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ethnicity', 'relation'], dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.columns[tf.isin({'?'}).sum() > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d5831062",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf.replace({'?' : np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "17c22ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf['relation'] = tf['relation'].fillna('Self')\n",
    "tf['ethnicity'] = tf['ethnicity'].fillna('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "525e49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Label Encoder to all Object type columns \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "tf[tf.select_dtypes(include = ['object']).columns] = tf[tf.select_dtypes(include = ['object']).columns].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9e8d818f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.445319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.914467</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.057229</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553447</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.799885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.581115</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.501526</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11.779210</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.223869</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.717321</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         1         0         0         0         1         0         0   \n",
       "2         1         0         0         1         0         1         0   \n",
       "3         1         1         1         0         1         0         1   \n",
       "4         1         0         0         1         1         0         0   \n",
       "\n",
       "   A8_Score  A9_Score  A10_Score        age  gender  ethnicity  jaundice  \\\n",
       "0         1         0          0  13.445319       1          0         0   \n",
       "1         0         0          0  25.057229       0         10         1   \n",
       "2         1         0          0  28.799885       0          0         0   \n",
       "3         0         1          1  16.501526       0          4         1   \n",
       "4         1         1          0  54.223869       0          9         0   \n",
       "\n",
       "   austim  contry_of_res  used_app_before     result  age_desc  relation  \n",
       "0       0             40                0  -0.914467         0         4  \n",
       "1       0             29                0   4.553447         0         2  \n",
       "2       0              6                0  -1.581115         0         4  \n",
       "3       0              8                0  11.779210         0         3  \n",
       "4       0              5                0  10.717321         0         4  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "82be66b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logreg.predict(tf)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70921fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "    \n",
    "# field names \n",
    "fields = ['ID', 'Class/ASD'] \n",
    "    \n",
    "# name of csv file \n",
    "filename = \"Predicted_Values_LogReg.csv\"\n",
    "    \n",
    "# writing to csv file \n",
    "with open(filename, 'a', newline='') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile, dialect='excel') \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "        \n",
    "    # writing the data rows \n",
    "    for w in range(0, len(y_pred)):\n",
    "        csvwriter.writerow([w+1, y_pred[w]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f38cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
